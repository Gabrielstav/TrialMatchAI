================================================================================
NER (Named Entity Recognition) Integration Documentation
================================================================================
Status: DEFERRED - Deploy without NER first, add later

This document describes what's needed to enable NER in the TrialMatchAI pipeline.
NER is currently DISABLED via config: "bio_med_ner": { "enabled": false }

================================================================================
OVERVIEW
================================================================================

NER provides two functions in the pipeline:
1. SYNONYM EXPANSION - Extracts disease/gene synonyms to improve search recall
2. ENTITY-ENRICHED SEARCH - Searches pre-indexed entity synonyms in ES

Without NER, the pipeline still works but with potentially lower search quality.
The LLM-based phenopacket processing extracts conditions - NER just adds synonyms.

================================================================================
ARCHITECTURE (4 Services)
================================================================================

┌────────────────────┬───────┬──────────────────┬───────────┬──────────────────────────────────┐
│      Service       │ Port  │    Technology    │  Memory   │             Purpose              │
├────────────────────┼───────┼──────────────────┼───────────┼──────────────────────────────────┤
│ BioMedNER          │ 18894 │ Python (RoBERTa) │ ~8GB GPU  │ Core biomedical NER              │
├────────────────────┼───────┼──────────────────┼───────────┼──────────────────────────────────┤
│ GNER               │ 18783 │ Python (GLiNER)  │ ~4GB GPU  │ Clinical-trial specific entities │
├────────────────────┼───────┼──────────────────┼───────────┼──────────────────────────────────┤
│ Disease Normalizer │ 18892 │ Java JAR         │ 16GB heap │ Disease → UMLS/MeSH mapping      │
├────────────────────┼───────┼──────────────────┼───────────┼──────────────────────────────────┤
│ Gene Normalizer    │ 18888 │ Java JAR         │ 20GB heap │ Gene → NCBI mapping (GNormPlus)  │
└────────────────────┴───────┴──────────────────┴───────────┴──────────────────────────────────┘

Total memory requirement: ~48GB (8+4 GPU + 36 Java heap)
Startup script: source/biomedner_services/run_biomedner.sh

================================================================================
SPACE REQUIREMENTS (~16-17 GB total)
================================================================================

Component                                          Size      Location
─────────────────────────────────────────────────────────────────────────────────
Parser/resources/normalization/normalizers/        7.0 GB    source/Parser/resources/
  - neural_norm_caches/ (FAISS indices)            4.5 GB
  - gene/ (GNormPlus data)                         2.6 GB
  - disease/                                       216 KB
Parser/resources/normalization/dictionary/         207 MB    source/Parser/resources/
Parser/resources/GNormPlusJava/                    2.4 GB    source/Parser/resources/
models/finetuned_model_roberta/                    5.4 GB    models/models/
GLiNER model (gliner-community/gliner_large-v2.5)  ~1.5 GB   HuggingFace (bake into image)
─────────────────────────────────────────────────────────────────────────────────
TOTAL                                              ~16-17 GB

================================================================================
WHAT'S ALREADY IN vm-deployment/models (for NER)
================================================================================

These components are ALREADY staged and ready:

✓ finetuned_roberta          5.4 GB   vm-deployment/models/finetuned/finetuned_roberta/
✓ neural_norm_caches         4.5 GB   vm-deployment/models/neural_norm_caches/
✓ biosyn-sapbert-bc5cdr-disease  418 MB   vm-deployment/models/
✓ biosyn-sapbert-bc5cdr-chemical 418 MB   vm-deployment/models/
✓ biosyn-sapbert-bc2gn           419 MB   vm-deployment/models/

Subtotal already staged: ~11.2 GB

================================================================================
WHAT'S MISSING (must add for NER to work)
================================================================================

These components are NOT yet in vm-deployment/ and must be added:

1. GLiNER Model (~1.5 GB)
   Source: HuggingFace gliner-community/gliner_large-v2.5
   Action: Must bake into apptainer at build time (no runtime downloads on HPC)

2. GNormPlusJava (2.4 GB)
   Source: source/Parser/resources/GNormPlusJava/
   Action: Copy to vm-deployment/ or include in apptainer
   Contents: Java libraries for gene normalization

3. Gene Normalizer Data (2.6 GB)
   Source: source/Parser/resources/normalization/normalizers/gene/
   Action: Copy to vm-deployment/ or include in apptainer
   Contents: GNormPlus dictionaries and index files

4. Disease Normalizer Resources (216 KB)
   Source: source/Parser/resources/normalization/normalizers/disease/
   Action: Copy to vm-deployment/

5. Dictionaries (207 MB)
   Source: source/Parser/resources/normalization/dictionary/
   Action: Copy to vm-deployment/
   Contents: dict_Gene.txt, dict_Disease.txt, dict_CellType.txt,
             dict_ChemicalsDrugs.txt, dict_Procedures.txt, dict_SignSymptom.txt

6. Java Runtime Environment (JRE)
   Version: Java 11+ recommended
   Action: Install in apptainer definition file
   Note: Required for disease_normalizer_21.jar and gnormplus-normalization_21.jar

Missing subtotal: ~6.7 GB + JRE

================================================================================
APPTAINER REQUIREMENTS
================================================================================

Add to trialmatchai.def:

1. Install Java:
   %post
       apt-get update && apt-get install -y openjdk-11-jre-headless

2. Download GLiNER at build time:
   %post
       python -c "from gliner import GLiNER; GLiNER.from_pretrained('gliner-community/gliner_large-v2.5')"

3. Copy NER resources into image or mount at runtime

================================================================================
SBATCH REQUIREMENTS
================================================================================

Memory: Request at least 64GB (48GB for NER services + buffer)
GPU: 1x GPU with 12GB+ VRAM for BioMedNER + GNER

Example SLURM directives:
#SBATCH --mem=64G
#SBATCH --gres=gpu:1

================================================================================
CONFIGURATION
================================================================================

To enable NER, set in config.json:

{
  "bio_med_ner": {
    "enabled": true,          // <-- Change to true
    "biomedner_port": 18894,
    "gner_port": 18783,
    "gene_norm_port": 18888,
    "disease_norm_port": 18892,
    "biomedner_home": "Parser/",
    "use_neural_normalizer": true,
    "no_cuda": false
  }
}

================================================================================
STARTUP SEQUENCE
================================================================================

When enabled, the pipeline will:
1. Run source/biomedner_services/run_biomedner.sh
2. Start 4 background services (takes ~30-60 seconds to initialize)
3. Services listen on localhost ports 18894, 18783, 18888, 18892

The main pipeline waits for services before proceeding.

================================================================================
FUTURE WORK / TODO
================================================================================

[ ] Copy missing NER resources to vm-deployment/:
    - GNormPlusJava/
    - normalizers/gene/
    - normalizers/disease/
    - dictionary/

[ ] Update trialmatchai.def to:
    - Install Java JRE
    - Bake GLiNER model into image
    - Set up paths for NER resources

[ ] Update sbatch scripts to allocate sufficient memory

[ ] Test NER services start correctly in apptainer

[ ] Consider: Can we run with just BioMedNER+GNER (Python only)?
    - Skip Java normalizers to save memory
    - Use neural normalization (BioSyn) only
    - Would reduce memory from 48GB to ~12GB

================================================================================